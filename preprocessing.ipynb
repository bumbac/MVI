{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914ac47d-897b-42dd-875f-8da1dff2a18d",
   "metadata": {},
   "source": [
    "## Preprocessing of the training and evaluation data\n",
    "\n",
    "The audio recordings come from YouTube podcasts in spanish language. Noise taken from DEMAND dataset. The list is available in the `sources.txt` file.\n",
    "\n",
    "The preprocessing consists in three steps:\n",
    "\n",
    "1. Downsample the audio recording wav 44.1kHz to wav 16kHz and convert to 1 channel. It loses some quality but it improves the training time. It was recommended in the paper. First and last minute of the recording is removed because of music.\n",
    "\n",
    "    `ffmpeg -ss 60 -i input -ar 16000 -ac 1 output`\n",
    "\n",
    "2. Create a copy of audio recording and add noise.\n",
    "    2. Noise is taken from DEMAND dataset as recommended in the paper.\n",
    "3. Tokenize the audio in samples 3-8 seconds long on silence.\n",
    "4. Split the data to train and evaluation set, create pairs (clean, noisy).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "227ac943-8413-460b-b444-bee65882c21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import auditok as at\n",
    "import librosa\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9ec60d-d888-46ac-b047-69d5759c88e8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00437f79-b7bf-4bd1-ba0e-ae91f39c8dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_src = [\"OMEETING\", \"OOFFICE\", \"PRESTO\", \"SPSQUARE\"]\n",
    "clean_src = ['podcast1_16_5.wav', 'podcast2_16_5.wav', 'podcast3_16_5.wav', 'podcast4_16_5.wav']\n",
    "original_dir = \"data/in/original/\"\n",
    "diff_noise_dir = \"data/noise/\"\n",
    "noise_idx = 0\n",
    "ch_names = [\"/ch%.2d.wav\" % i for i in range(1,16)]\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03b903fb-f128-453c-8627-513903a1d987",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['podcast1_16_5.wav', 'podcast2_16_5.wav', 'podcast3_16_5.wav', 'podcast4_16_5.wav'])\n",
      "dict_keys(['podcast1_16_5.wav', 'podcast2_16_5.wav', 'podcast3_16_5.wav', 'podcast4_16_5.wav', 'OMEETING/ch01.wav', 'OMEETING/ch02.wav', 'OMEETING/ch03.wav', 'OMEETING/ch04.wav', 'OMEETING/ch05.wav', 'OMEETING/ch06.wav', 'OMEETING/ch07.wav', 'OMEETING/ch08.wav', 'OMEETING/ch09.wav', 'OMEETING/ch10.wav', 'OMEETING/ch11.wav', 'OMEETING/ch12.wav', 'OMEETING/ch13.wav', 'OMEETING/ch14.wav', 'OMEETING/ch15.wav', 'OOFFICE/ch01.wav', 'OOFFICE/ch02.wav', 'OOFFICE/ch03.wav', 'OOFFICE/ch04.wav', 'OOFFICE/ch05.wav', 'OOFFICE/ch06.wav', 'OOFFICE/ch07.wav', 'OOFFICE/ch08.wav', 'OOFFICE/ch09.wav', 'OOFFICE/ch10.wav', 'OOFFICE/ch11.wav', 'OOFFICE/ch12.wav', 'OOFFICE/ch13.wav', 'OOFFICE/ch14.wav', 'OOFFICE/ch15.wav', 'PRESTO/ch01.wav', 'PRESTO/ch02.wav', 'PRESTO/ch03.wav', 'PRESTO/ch04.wav', 'PRESTO/ch05.wav', 'PRESTO/ch06.wav', 'PRESTO/ch07.wav', 'PRESTO/ch08.wav', 'PRESTO/ch09.wav', 'PRESTO/ch10.wav', 'PRESTO/ch11.wav', 'PRESTO/ch12.wav', 'PRESTO/ch13.wav', 'PRESTO/ch14.wav', 'PRESTO/ch15.wav', 'SPSQUARE/ch01.wav', 'SPSQUARE/ch02.wav', 'SPSQUARE/ch03.wav', 'SPSQUARE/ch04.wav', 'SPSQUARE/ch05.wav', 'SPSQUARE/ch06.wav', 'SPSQUARE/ch07.wav', 'SPSQUARE/ch08.wav', 'SPSQUARE/ch09.wav', 'SPSQUARE/ch10.wav', 'SPSQUARE/ch11.wav', 'SPSQUARE/ch12.wav', 'SPSQUARE/ch13.wav', 'SPSQUARE/ch14.wav', 'SPSQUARE/ch15.wav'])\n"
     ]
    }
   ],
   "source": [
    "sr = 16000\n",
    "for filename in clean_src:\n",
    "    clean_file = original_dir + filename\n",
    "    clean, sr = librosa.load(clean_file, sr=sr)\n",
    "    data[filename] = clean\n",
    "print(data.keys())\n",
    "for noise_dir in noise_src:\n",
    "    for ch in ch_names:\n",
    "        noise_file = diff_noise_dir + noise_dir + ch\n",
    "        noise, sr = librosa.load(noise_file, sr=sr)\n",
    "        minute = len(noise) // 5 + 1\n",
    "        noise = noise[:minute]\n",
    "        data[noise_dir + ch] = noise\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d69fb3a-4e61-437e-88d4-1aba0b633584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "podcast1_16_5.wav\n",
      "podcast2_16_5.wav\n",
      "podcast3_16_5.wav\n",
      "podcast1_16_5.wav\n",
      "podcast2_16_5.wav\n",
      "podcast3_16_5.wav\n",
      "podcast1_16_5.wav\n",
      "podcast2_16_5.wav\n",
      "podcast3_16_5.wav\n",
      "podcast4_16_5.wav\n",
      "data/in/noisy/4_SPSQUAREch01.wav\n",
      "data/in/noisy/4_SPSQUAREch02.wav\n",
      "data/in/noisy/4_SPSQUAREch03.wav\n",
      "data/in/noisy/4_SPSQUAREch04.wav\n",
      "data/in/noisy/4_SPSQUAREch05.wav\n"
     ]
    }
   ],
   "source": [
    "noise_src = [\"OMEETING\", \"OOFFICE\", \"PRESTO\"]\n",
    "clean_src = ['podcast1_16_5.wav', 'podcast2_16_5.wav', 'podcast3_16_5.wav']\n",
    "parts_n = 5\n",
    "sr = 16000\n",
    "for noise_dir in noise_src:\n",
    "    noise_idx = 0\n",
    "    for filename in clean_src:\n",
    "        print(filename)\n",
    "        clean = data[filename]\n",
    "        parts = np.array_split(clean, parts_n)\n",
    "        for i in range(parts_n):\n",
    "            ch = ch_names[noise_idx]\n",
    "            noise_idx += 1\n",
    "            noise = data[noise_dir + ch]\n",
    "            lim = min(parts[i].shape, noise.shape)[0]\n",
    "            clean = clean[:lim]\n",
    "            noise = noise[:lim]\n",
    "            noisy_data = (clean+noise) / 2\n",
    "            filename_clean_file = \"data/in/clean/\" + filename[len(\"podcast\"):-len(\"_16_5.wav\")] +\"_\"+noise_dir+ch[1:]\n",
    "            filename_noisy_file = \"data/in/noisy/\" + filename[len(\"podcast\"):-len(\"_16_5.wav\")] +\"_\"+noise_dir+ch[1:]\n",
    "            sf.write(filename_noisy_file, noisy_data, sr, subtype='PCM_16')\n",
    "            sf.write(filename_clean_file, clean, sr, subtype='PCM_16')\n",
    "\n",
    "for noise_dir in [\"SPSQUARE\"]:\n",
    "    noise_idx = 0\n",
    "    for filename in [\"podcast4_16_5.wav\"]:\n",
    "        print(filename)\n",
    "        clean = data[filename]\n",
    "        parts = np.array_split(clean, parts_n)\n",
    "        for i in range(parts_n):\n",
    "            ch = ch_names[noise_idx]\n",
    "            noise_idx += 1\n",
    "            noise = data[noise_dir + ch]\n",
    "            lim = min(parts[i].shape, noise.shape)[0]\n",
    "            clean = clean[:lim]\n",
    "            noise = noise[:lim]\n",
    "            noisy_data = (clean+noise) / 2\n",
    "            filename_clean_file = \"data/in/clean/\" + filename[len(\"podcast\"):-len(\"_16_5.wav\")] +\"_\"+noise_dir+ch[1:]\n",
    "            filename_noisy_file = \"data/in/noisy/\" + filename[len(\"podcast\"):-len(\"_16_5.wav\")] +\"_\"+noise_dir+ch[1:]\n",
    "            print(filename_noisy_file)\n",
    "            sf.write(filename_noisy_file, noisy_data, sr, subtype='PCM_16')\n",
    "            sf.write(filename_clean_file, clean, sr, subtype='PCM_16')\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d742f839-427a-4c1e-8ffa-b79b0a129a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = at.load(\"data/in/noisy/2_OOFFICEch06.wav\", sr=sr) # returns an AudioRegion object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5ea9fde-273b-4b6b-86fc-b679ac4c05e3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/in/noisy/2_OOFFICEch06.wav\n",
      "data/in/noisy/4_SPSQUAREch02.wav\n",
      "data/in/noisy/1_OMEETINGch01.wav\n",
      "data/in/noisy/2_OMEETINGch08.wav\n",
      "data/in/noisy/3_PRESTOch15.wav\n",
      "data/in/noisy/3_OMEETINGch12.wav\n",
      "data/in/noisy/1_OOFFICEch05.wav\n",
      "data/in/noisy/4_SPSQUAREch03.wav\n",
      "data/in/noisy/1_OMEETINGch03.wav\n",
      "data/in/noisy/1_PRESTOch05.wav\n",
      "data/in/noisy/2_OOFFICEch07.wav\n",
      "data/in/noisy/3_OOFFICEch15.wav\n",
      "data/in/noisy/2_OOFFICEch09.wav\n",
      "data/in/noisy/2_PRESTOch08.wav\n",
      "data/in/noisy/2_OOFFICEch08.wav\n",
      "data/in/noisy/1_OOFFICEch02.wav\n",
      "data/in/noisy/1_OOFFICEch03.wav\n",
      "data/in/noisy/1_PRESTOch03.wav\n",
      "data/in/noisy/3_OMEETINGch15.wav\n",
      "data/in/noisy/1_PRESTOch04.wav\n",
      "data/in/noisy/3_PRESTOch12.wav\n",
      "data/in/noisy/3_PRESTOch11.wav\n",
      "data/in/noisy/3_OMEETINGch14.wav\n",
      "data/in/noisy/2_PRESTOch07.wav\n",
      "data/in/noisy/2_OOFFICEch10.wav\n",
      "data/in/noisy/2_PRESTOch10.wav\n",
      "data/in/noisy/1_PRESTOch02.wav\n",
      "data/in/noisy/2_PRESTOch09.wav\n",
      "data/in/noisy/3_OOFFICEch13.wav\n",
      "data/in/noisy/2_OMEETINGch06.wav\n",
      "data/in/noisy/2_OMEETINGch10.wav\n",
      "data/in/noisy/3_OOFFICEch14.wav\n",
      "data/in/noisy/3_OOFFICEch12.wav\n",
      "data/in/noisy/1_OOFFICEch04.wav\n",
      "data/in/noisy/2_OMEETINGch09.wav\n",
      "data/in/noisy/3_OMEETINGch11.wav\n",
      "data/in/noisy/4_SPSQUAREch05.wav\n",
      "data/in/noisy/3_PRESTOch14.wav\n",
      "data/in/noisy/1_OMEETINGch05.wav\n",
      "data/in/noisy/1_OMEETINGch04.wav\n",
      "data/in/noisy/1_OOFFICEch01.wav\n",
      "data/in/noisy/3_OOFFICEch11.wav\n",
      "data/in/noisy/3_OMEETINGch13.wav\n",
      "data/in/noisy/2_OMEETINGch07.wav\n",
      "data/in/noisy/4_SPSQUAREch01.wav\n",
      "data/in/noisy/2_PRESTOch06.wav\n",
      "data/in/noisy/1_OMEETINGch02.wav\n",
      "data/in/noisy/3_PRESTOch13.wav\n",
      "data/in/noisy/4_SPSQUAREch04.wav\n",
      "data/in/noisy/1_PRESTOch01.wav\n"
     ]
    }
   ],
   "source": [
    "parts_n = 5\n",
    "final = \"X_0_00_YYYY.wav\"\n",
    "noisy_dir = \"data/in/noisy/\"\n",
    "clean_dir = \"data/in/clean/\"\n",
    "for filename in os.listdir(noisy_dir):\n",
    "    print(noisy_dir + filename)\n",
    "    audio_regions = at.split(\n",
    "        noisy_dir + filename,\n",
    "        min_dur=3,     # minimum duration of a valid audio event in seconds\n",
    "        max_dur=9,       # maximum duration of an event\n",
    "        max_silence=0.3, # maximum duration of tolerated continuous silence within an event\n",
    "        energy_threshold=55 # threshold of detection\n",
    "    )\n",
    "    for i, sample in enumerate(audio_regions):\n",
    "        sample.save(\"data/in/split/noisy/\"+str(i)+\"_\"+filename)\n",
    "\n",
    "\n",
    "for filename in os.listdir(clean_dir):\n",
    "    audio_regions = at.split(\n",
    "        clean_dir + filename,\n",
    "        min_dur=3,     # minimum duration of a valid audio event in seconds\n",
    "        max_dur=9,       # maximum duration of an event\n",
    "        max_silence=0.3, # maximum duration of tolerated continuous silence within an event\n",
    "        energy_threshold=55 # threshold of detection\n",
    "    )\n",
    "    for i, sample in enumerate(audio_regions):\n",
    "        sample.save(\"data/in/split/clean/\"+str(i)+\"_\"+filename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvi-venv",
   "language": "python",
   "name": "mvi-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
